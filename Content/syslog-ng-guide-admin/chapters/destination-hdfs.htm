<?xml version="1.0" encoding="UTF-8"?>
%entities;]&gt;
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd">
 <body name="configuring-destinations-hdfs" oldrole="section">
  <h1 name="configuring-destinations-hdfs" oldrole="section">
   <span class="Code" oldrole="parameter">
    hdfs
   </span>
   : Storing messages on the Hadoop Distributed File System (HDFS)
  </h1>
  <MadCap:keyword term="destination drivers:[&lt;span class=&quot;Code&quot; oldrole=&quot;parameter&quot;&gt;java()&lt;/span&gt;, ' driver']">
  </MadCap:keyword>
  <MadCap:keyword term='destination drivers:[&lt;span class="Code" oldrole="parameter"&gt;hdfs&lt;/span&gt;]'>
  </MadCap:keyword>
  <p oldrole="para">
   Starting with version
   <MadCap:conditionaltext MadCap:conditions="pe">
    5.3
   </MadCap:conditionaltext>
   <MadCap:conditionaltext MadCap:conditions="ose">
    3.7
   </MadCap:conditionaltext>
   ,
   <MadCap:variable name="General.abbrev">
    abbrev
   </MadCap:variable>
   can send plain-text log files to the
   <a href="http://hadoop.apache.org/">
    Hadoop Distributed File System (HDFS)
   </a>
   , allowing you to store your log data on a distributed, scalable file system. This is especially useful if you have huge amounts of log messages that would be difficult to store otherwise, or if you want to process your messages using Hadoop tools (for example, Apache Pig).
  </p>
  <p oldrole="para">
   For more information about the benefits of using syslog-ng as a data collection, processing, and filtering tool in a Hadoop environment, see the blog post
   <a href="https://syslog-ng.com/blog/filling-your-data-lake-with-log-messages-the-syslog-ng-hadoop-hdfs-destination/">
    Filling your data lake with log messages: the syslog-ng Hadoop (HDFS) destination
   </a>
   .
  </p>
  <p oldrole="para">
   Note the following limitations when using the
   <entity>
    abbrev
   </entity>
   <span class="Code" oldrole="parameter">
    hdfs
   </span>
   destination:
  </p>
  <ul oldrole="itemizedlist">
   <MadCap:snippetBlock src="../../shared/chunk/listitem-java-supported-platforms.htm">
   </MadCap:snippetBlock>
   <li oldrole="listitem">
    <p oldrole="para">
     Since
     <entity>
      abbrev
     </entity>
     uses the official Java HDFS client, the
     <span class="Code" oldrole="parameter">
      hdfs
     </span>
     destination has significant memory usage (about 400MB).
    </p>
   </li>
   <li oldrole="listitem">
    <MadCap:snippetBlock src="../../shared/chunk/para-hdfs-flush.htm">
    </MadCap:snippetBlock>
   </li>
   <MadCap:snippetBlock src="../../shared/chunk/listitem-java-internal-messages.htm">
   </MadCap:snippetBlock>
  </ul>
  <p>
   <b oldrole="formalpara">
    Declaration:
   </b>
  </p>
  <p oldrole="para">
  </p>
  <p class="Code" oldrole="synopsis">
   @module mod-java
@include "scl.conf"

hdfs(
    client-lib-dir("/opt/syslog-ng/lib/syslog-ng/java-modules/:&lt;path-to-preinstalled-hadoop-libraries&gt;")
    hdfs-uri("hdfs://NameNode:8020")
    hdfs-file("&lt;path-to-logfile&gt;")
);
  </p>
  <example xml:id="example-destination-hdfs">
   <title>
    Storing logfiles on HDFS
   </title>
   <p oldrole="para">
    The following example defines an
    <span class="Code" oldrole="parameter">
     hdfs
    </span>
    destination using only the required parameters.
   </p>
   <p class="Code" oldrole="synopsis">
    @module mod-java
@include "scl.conf"

destination d_hdfs {
    hdfs(
        client-lib-dir("/opt/syslog-ng/lib/syslog-ng/java-modules/:/opt/hadoop/libs")
        hdfs-uri("hdfs://10.140.32.80:8020")
        hdfs-file("/user/log/logfile.txt")
    );
};
   </p>
  </example>
  <ul oldrole="itemizedlist">
   <li oldrole="listitem">
    <p oldrole="para">
     To install the software required for the
     <span class="Code" oldrole="parameter">
      hdfs
     </span>
     destination, see
     <xref linkend="destination-hdfs-prerequisites">
     </xref>
     .
    </p>
   </li>
   <li oldrole="listitem">
    <p oldrole="para">
     For details on how the
     <span class="Code" oldrole="parameter">
      hdfs
     </span>
     destination works, see
     <xref linkend="destination-hdfs-interaction">
     </xref>
     .
    </p>
   </li>
   <li oldrole="listitem">
    <p oldrole="para">
     For details on using MapR-FS, see
     <xref linkend="destination-hdfs-maprfs">
     </xref>
     .
    </p>
   </li>
   <li oldrole="listitem">
    <p oldrole="para">
     For details on using Kerberos authentication, see
     <xref linkend="destination-hdfs-kerberos-authentication">
     </xref>
     .
    </p>
   </li>
   <li oldrole="listitem">
    <p oldrole="para">
     For the list of options, see
     <xref linkend="reference-destination-hdfs">
     </xref>
     .
    </p>
   </li>
  </ul>
  <p condition="ose" oldrole="para">
   The
   <span class="Code" oldrole="parameter">
    hdfs()
   </span>
   driver is actually a reusable configuration snippet configured to receive log messages using the Java language-binding of
   <entity>
    abbrev
   </entity>
   . For details on using or writing such configuration snippets, see
   <xref linkend="config-blocks">
   </xref>
   . You can find the source of the hdfs configuration snippet on
   <a href="https://github.com/balabit/syslog-ng/blob/master/scl/hdfs/plugin.conf">
    GitHub
   </a>
   . For details on extending
   <entity>
    abbrev
   </entity>
   in Java, see the
   <a href="https://syslog-ng.gitbooks.io/getting-started/content/chapters/chapter_5/section_2.html">
    Getting started with syslog-ng development
   </a>
   guide.
  </p>
  <MadCap:snippetBlock src="destination-hdfs-prerequisites.htm">
  </MadCap:snippetBlock>
  <MadCap:snippetBlock src="destination-hdfs-interaction.htm">
  </MadCap:snippetBlock>
  <MadCap:snippetBlock src="destination-hdfs-maprfs.htm">
  </MadCap:snippetBlock>
  <h2 name="destination-hdfs-kerberos-authentication">
   Kerberos authentication with syslog-ng hdfs() destination
  </h2>
  <p oldrole="para">
   Version
   <phrase condition="ose">
    3.10
   </phrase>
   <phrase condition="pe">
    7.0.3
   </phrase>
   and later supports Kerberos authentication to authenticate the connection to your Hadoop cluster.
   <entity>
    abbrev
   </entity>
   assumes that you already have a Hadoop and Kerberos infrastructure.
  </p>
  <table cellspacing="0" class="TableStyle-NoteTable_Blue_DoNotEdit" oldrole="note" style="width: 100%;mc-table-style: url('../../Resources/TableStyles/NoteTable_Blue_DoNotEdit.css');">
   <col class="TableStyle-NoteTable_Blue_DoNotEdit-Column-Column1" style="width: 0.3in;">
   </col>
   <col class="TableStyle-NoteTable_Blue_DoNotEdit-Column-Column2">
   </col>
   <tbody>
    <tr class="TableStyle-NoteTable_Blue_DoNotEdit-Body-Body1">
     <td class="TableStyle-NoteTable_Blue_DoNotEdit-BodyB-Column1-Body1">
      <p>
       <img src="../../Resources/Images/Common/note.png"/>
      </p>
     </td>
     <td class="TableStyle-NoteTable_Blue_DoNotEdit-BodyA-Column2-Body1">
      <span class="AllNoteStyles">
       NOTE:
      </span>
      <p oldrole="para">
       If you configure Kerberos authentication for a
       <span class="Code" oldrole="parameter">
        hdfs()
       </span>
       destination, it affects all
       <span class="Code" oldrole="parameter">
        hdfs()
       </span>
       destinations. Kerberos and non-Kerberos
       <span class="Code" oldrole="parameter">
        hdfs()
       </span>
       destinations cannot be mixed in a
       <entity>
        abbrev
       </entity>
       configuration. This means that if one
       <span class="Code" oldrole="parameter">
        hdfs()
       </span>
       destination uses Kerberos authentication, you have to configure all other
       <span class="Code" oldrole="parameter">
        hdfs()
       </span>
       destinations to use Kerberos authentication too.
      </p>
      <p oldrole="para">
       Failing to do so results in non-Kerberos
       <span class="Code" oldrole="parameter">
        hdfs()
       </span>
       destinations being unable to authenticate to the HDFS server.
      </p>
     </td>
    </tr>
   </tbody>
  </table>
  <table cellspacing="0" class="TableStyle-NoteTable_Blue_DoNotEdit" oldrole="note" style="width: 100%;mc-table-style: url('../../Resources/TableStyles/NoteTable_Blue_DoNotEdit.css');">
   <col class="TableStyle-NoteTable_Blue_DoNotEdit-Column-Column1" style="width: 0.3in;">
   </col>
   <col class="TableStyle-NoteTable_Blue_DoNotEdit-Column-Column2">
   </col>
   <tbody>
    <tr class="TableStyle-NoteTable_Blue_DoNotEdit-Body-Body1">
     <td class="TableStyle-NoteTable_Blue_DoNotEdit-BodyB-Column1-Body1">
      <p>
       <img src="../../Resources/Images/Common/note.png"/>
      </p>
     </td>
     <td class="TableStyle-NoteTable_Blue_DoNotEdit-BodyA-Column2-Body1">
      <span class="AllNoteStyles">
       NOTE:
      </span>
      <p oldrole="para">
       If you want to configure your
       <span class="Code" oldrole="parameter">
        hdfs()
       </span>
       destination to stop using Kerberos authentication, namely, to remove Kerberos-related options from the
       <span class="Code" oldrole="parameter">
        hdfs()
       </span>
       destination configuration, make sure to restart
       <entity>
        abbrev
       </entity>
       for the changes to take effect.
      </p>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   <b oldrole="formalpara">
    Prerequisites:
   </b>
  </p>
  <p oldrole="para">
  </p>
  <ul oldrole="itemizedlist">
   <li oldrole="listitem">
    <p oldrole="para">
     You have configured your Hadoop infrastructure to use Kerberos authentication.
    </p>
   </li>
   <li oldrole="listitem">
    <p oldrole="para">
     You have a keytab file and a principal for the host running
     <entity>
      abbrev
     </entity>
     . For details, see the
     <a href="http://web.mit.edu/Kerberos/krb5-1.5/krb5-1.5.4/doc/krb5-install/The-Keytab-File.html">
      Kerberos documentation
     </a>
     .
    </p>
   </li>
   <li oldrole="listitem">
    <p oldrole="para">
     You have installed and configured the Kerberos client packages on the host running
     <entity>
      abbrev
     </entity>
     . (That is, Kerberos authentication works for the host, for example, from the command line using the
     <b oldrole="command">
      kinit user@REALM -k -t &lt;keytab_file&gt;
     </b>
     command.)
    </p>
   </li>
  </ul>
  <MadCap:snippetBlock src="../../shared/chunk/synopsis-hdfs-kerberos-example.htm">
  </MadCap:snippetBlock>
  <h2 name="reference-destination-hdfs">
   HDFS destination options
  </h2>
  <indexterm>
   <primary>
    destination drivers
   </primary>
   <secondary>
    <span class="Code" oldrole="parameter">
     java()
    </span>
    driver
   </secondary>
  </indexterm>
  <indexterm>
   <primary>
    destination drivers
   </primary>
   <secondary>
    <span class="Code" oldrole="parameter">
     hdfs
    </span>
   </secondary>
  </indexterm>
  <p oldrole="para">
   The
   <span class="Code" oldrole="parameter">
    hdfs
   </span>
   destination stores the log messages in files on the Hadoop Distributed File System (HDFS). The
   <span class="Code" oldrole="parameter">
    hdfs
   </span>
   destination has the following options.
  </p>
  <p oldrole="para">
   The following options are required:
   <span class="Code" oldrole="parameter">
    hdfs-file()
   </span>
   ,
   <span class="Code" oldrole="parameter">
    hdfs-uri()
   </span>
   . Note that to use
   <span class="Code" oldrole="parameter">
    hdfs
   </span>
   , you must add the following lines to the beginning of your
   <entity>
    abbrev
   </entity>
   configuration:
  </p>
  <p class="Code" oldrole="synopsis">
   @module mod-java
@include "scl.conf"
  </p>
  <simplesect>
   <MadCap:snippetBlock src="../../shared/chunk/option-destination-java-class-path.htm">
   </MadCap:snippetBlock>
   <p oldrole="para">
    For the
    <span class="Code" oldrole="parameter">
     hdfs
    </span>
    destination, include the path to the directory where you copied the required libraries (see
    <xref linkend="destination-hdfs-prerequisites">
    </xref>
    ), for example,
    <span class="Code" oldrole="userinput">
     client-lib-dir("/opt/syslog-ng/lib/syslog-ng/java-modules/*.jar:/opt/hadoop/libs/*.jar")
    </span>
    .
   </p>
  </simplesect>
  <simplesect>
   <MadCap:snippetBlock src="../../shared/chunk/option-destination-diskbuffer.htm">
   </MadCap:snippetBlock>
  </simplesect>
  <simplesect>
   <MadCap:snippetBlock src="../../shared/chunk/option-destination-frac-digits.htm">
   </MadCap:snippetBlock>
  </simplesect>
  <simplesect xml:id="option-hdfs-append-enabled">
   <MadCap:snippetBlock src="../../shared/chunk/option-destination-hdfs-append-enabled.htm">
   </MadCap:snippetBlock>
  </simplesect>
  <simplesect xml:id="hdfs-option-hdfs-archive-dir">
   <title>
    hdfs-archive-dir()
   </title>
   <indexterm type="parameter">
    <primary>
     hdfs-archive-dir()
    </primary>
    <secondary>
     hdfs
    </secondary>
   </indexterm>
   <indexterm type="parameter">
    <primary>
     hdfs
    </primary>
    <secondary>
     hdfs-archive-dir
    </secondary>
   </indexterm>
   <informaltable colsep="0" frame="topbot" rowsep="0">
    <tgroup cols="2">
     <colspec colnum="1" colwidth="40pt">
     </colspec>
     <tbody>
      <row>
       <entry>
        Type:
       </entry>
       <entry>
        string
       </entry>
      </row>
      <row>
       <entry>
        Default:
       </entry>
       <entry>
        N/A
       </entry>
      </row>
     </tbody>
    </tgroup>
   </informaltable>
   <p oldrole="para">
    <i oldrole="emphasis" role="bold">
     Description:
    </i>
    The path where
    <entity>
     abbrev
    </entity>
    will move the closed log files. If
    <entity>
     abbrev
    </entity>
    cannot move the file for some reason (for example,
    <entity>
     abbrev
    </entity>
    cannot connect to the HDFS NameNode), the file remains at its original location. For example,
    <span class="Code" oldrole="userinput">
     hdfs-archive-dir("/usr/hdfs/archive/")
    </span>
    .
   </p>
  </simplesect>
  <simplesect xml:id="hdfs-option-hdfs-file">
   <title>
    hdfs-file()
   </title>
   <indexterm type="parameter">
    <primary>
     hdfs-file()
    </primary>
    <secondary>
     hdfs
    </secondary>
   </indexterm>
   <indexterm type="parameter">
    <primary>
     hdfs
    </primary>
    <secondary>
     hdfs-file
    </secondary>
   </indexterm>
   <informaltable colsep="0" frame="topbot" rowsep="0">
    <tgroup cols="2">
     <colspec colnum="1" colwidth="40pt">
     </colspec>
     <tbody>
      <row>
       <entry>
        Type:
       </entry>
       <entry>
        string
       </entry>
      </row>
      <row>
       <entry>
        Default:
       </entry>
       <entry>
        N/A
       </entry>
      </row>
     </tbody>
    </tgroup>
   </informaltable>
   <p oldrole="para">
    <i oldrole="emphasis" role="bold">
     Description:
    </i>
    The path and name of the log file. For example,
    <span class="Code" oldrole="userinput">
     hdfs-file("/usr/hdfs/mylogfile.txt")
    </span>
    .
    <entity>
     abbrev
    </entity>
    checks if the path to the logfile exists. If a directory does not exist
    <entity>
     abbrev
    </entity>
    automatically creates it.
   </p>
   <p oldrole="para">
    <span class="Code" oldrole="parameter">
     hdfs-file()
    </span>
    supports the usage of macros. This means that
    <entity>
     abbrev
    </entity>
    can create files on HDFS dynamically, using macros in the file (or directory) name.
   </p>
   <table cellspacing="0" class="TableStyle-NoteTable_Blue_DoNotEdit" oldrole="note" style="width: 100%;mc-table-style: url('../../Resources/TableStyles/NoteTable_Blue_DoNotEdit.css');">
    <col class="TableStyle-NoteTable_Blue_DoNotEdit-Column-Column1" style="width: 0.3in;">
    </col>
    <col class="TableStyle-NoteTable_Blue_DoNotEdit-Column-Column2">
    </col>
    <tbody>
     <tr class="TableStyle-NoteTable_Blue_DoNotEdit-Body-Body1">
      <td class="TableStyle-NoteTable_Blue_DoNotEdit-BodyB-Column1-Body1">
       <p>
        <img src="../../Resources/Images/Common/note.png"/>
       </p>
      </td>
      <td class="TableStyle-NoteTable_Blue_DoNotEdit-BodyA-Column2-Body1">
       <span class="AllNoteStyles">
        NOTE:
       </span>
       <p oldrole="para">
        When a filename resolved from the macros contains a character that HDFS does not support,
        <entity>
         abbrev
        </entity>
        will not be able to create the file. Make sure that you use macros that do not contain unsupported characters.
       </p>
      </td>
     </tr>
    </tbody>
   </table>
   <example>
    <title>
     Using macros in filenames
    </title>
    <p oldrole="para">
     In the following example, a
     <span class="Code" oldrole="filename">
      /var/testdb_working_dir/$DAY-$HOUR.txt
     </span>
     file will be created (with a UUID suffix):
    </p>
    <p class="Code" oldrole="synopsis">
     destination d_hdfs_9bf3ff45341643c69bf46bfff940372a {
    hdfs(client-lib-dir(/hdfs-libs)
 hdfs-uri("hdfs://hdp2.syslog-ng.balabit:8020")
 hdfs-file("/var/testdb_working_dir/$DAY-$HOUR.txt"));
};
    </p>
    <p oldrole="para">
     As an example, if it is the 31st day of the month and it is 12 o'clock, then the name of the file will be
     <span class="Code" oldrole="filename">
      31-12.txt
     </span>
     .
    </p>
   </example>
  </simplesect>
  <simplesect xml:id="hdfs-option-hdfs-max-filename-length">
   <title>
    hdfs-max-filename-length()
   </title>
   <indexterm type="parameter">
    <primary>
     hdfs-max-filename-length()
    </primary>
    <secondary>
     hdfs
    </secondary>
   </indexterm>
   <indexterm type="parameter">
    <primary>
     hdfs
    </primary>
    <secondary>
     hdfs-max-filename-length
    </secondary>
   </indexterm>
   <informaltable colsep="0" frame="topbot" rowsep="0">
    <tgroup cols="2">
     <colspec colnum="1" colwidth="40pt">
     </colspec>
     <tbody>
      <row>
       <entry>
        Type:
       </entry>
       <entry>
        number
       </entry>
      </row>
      <row>
       <entry>
        Default:
       </entry>
       <entry>
        255
       </entry>
      </row>
     </tbody>
    </tgroup>
   </informaltable>
   <p oldrole="para">
    <i oldrole="emphasis" role="bold">
     Description:
    </i>
    The maximum length of the filename. This filename (including the UUID that
    <entity>
     abbrev
    </entity>
    appends to it) cannot be longer than what the file system permits. If the filename is longer than the value of
    <span class="Code" oldrole="parameter">
     hdfs-max-filename-length
    </span>
    ,
    <entity>
     abbrev
    </entity>
    will automatically truncate the filename. For example,
    <span class="Code" oldrole="userinput">
     hdfs-max-filename-length("255")
    </span>
    .
   </p>
  </simplesect>
  <simplesect xml:id="hdfs-option-hdfs-resources">
   <title>
    hdfs-resources()
   </title>
   <indexterm type="parameter">
    <primary>
     hdfs-resources()
    </primary>
    <secondary>
     hdfs
    </secondary>
   </indexterm>
   <indexterm type="parameter">
    <primary>
     hdfs
    </primary>
    <secondary>
     hdfs-resources
    </secondary>
   </indexterm>
   <informaltable colsep="0" frame="topbot" rowsep="0">
    <tgroup cols="2">
     <colspec colnum="1" colwidth="40pt">
     </colspec>
     <tbody>
      <row>
       <entry>
        Type:
       </entry>
       <entry>
        string
       </entry>
      </row>
      <row>
       <entry>
        Default:
       </entry>
       <entry>
        N/A
       </entry>
      </row>
     </tbody>
    </tgroup>
   </informaltable>
   <p oldrole="para">
    <i oldrole="emphasis" role="bold">
     Description:
    </i>
    The list of Hadoop resources to load, separated by semicolons. For example,
    <span class="Code" oldrole="userinput">
     hdfs-resources("/home/user/hadoop/core-site.xml;/home/user/hadoop/hdfs-site.xml")
    </span>
    .
   </p>
  </simplesect>
  <simplesect xml:id="hdfs-option-hdfs-uri">
   <title>
    hdfs-uri()
   </title>
   <indexterm type="parameter">
    <primary>
     hdfs-uri()
    </primary>
    <secondary>
     hdfs
    </secondary>
   </indexterm>
   <indexterm type="parameter">
    <primary>
     hdfs
    </primary>
    <secondary>
     hdfs-uri
    </secondary>
   </indexterm>
   <informaltable colsep="0" frame="topbot" rowsep="0">
    <tgroup cols="2">
     <colspec colnum="1" colwidth="40pt">
     </colspec>
     <tbody>
      <row>
       <entry>
        Type:
       </entry>
       <entry>
        string
       </entry>
      </row>
      <row>
       <entry>
        Default:
       </entry>
       <entry>
        N/A
       </entry>
      </row>
     </tbody>
    </tgroup>
   </informaltable>
   <p oldrole="para">
    <i oldrole="emphasis" role="bold">
     Description:
    </i>
    The URI of the HDFS NameNode is in
    <span class="Code" oldrole="userinput">
     hdfs://IPaddress:port
    </span>
    or
    <span class="Code" oldrole="userinput">
     hdfs://hostname:port
    </span>
    format. When using MapR-FS, the URI of the MapR-FS NameNode is in
    <span class="Code" oldrole="userinput">
     maprfs://IPaddress
    </span>
    or
    <span class="Code" oldrole="userinput">
     maprfs://hostname
    </span>
    format, for example:
    <span class="Code" oldrole="userinput">
     maprfs://10.140.32.80
    </span>
    . The IP address of the node can be IPv4 or IPv6. For example,
    <span class="Code" oldrole="userinput">
     hdfs-uri("hdfs://10.140.32.80:8020")
    </span>
    . The IPv6 address must be enclosed in square brackets (
    <i oldrole="emphasis">
     []
    </i>
    ) as specified by RFC 2732, for example,
    <span class="Code" oldrole="userinput">
     hdfs-uri("hdfs://[FEDC:BA98:7654:3210:FEDC:BA98:7654:3210]:8020")
    </span>
    .
   </p>
  </simplesect>
  <simplesect xml:id="hdfs-destination-jvm-options">
   <MadCap:snippetBlock src="../../shared/chunk/option-destination-jvm-options.htm">
   </MadCap:snippetBlock>
  </simplesect>
  <simplesect xml:id="hdfs-option-kerberos-keytab-file">
   <title>
    kerberos-keytab-file()
   </title>
   <indexterm type="parameter">
    <primary>
     kerberos-keytab-file()
    </primary>
    <secondary>
     hdfs
    </secondary>
   </indexterm>
   <indexterm type="parameter">
    <primary>
     hdfs
    </primary>
    <secondary>
     kerberos-keytab-file
    </secondary>
   </indexterm>
   <indexterm>
    <primary>
     kerberos
    </primary>
    <secondary>
     hdfs
    </secondary>
   </indexterm>
   <informaltable colsep="0" frame="topbot" rowsep="0">
    <tgroup cols="2">
     <colspec colnum="1" colwidth="40pt">
     </colspec>
     <tbody>
      <row>
       <entry>
        Type:
       </entry>
       <entry>
        string
       </entry>
      </row>
      <row>
       <entry>
        Default:
       </entry>
       <entry>
        N/A
       </entry>
      </row>
     </tbody>
    </tgroup>
   </informaltable>
   <p oldrole="para">
    <i oldrole="emphasis" role="bold">
     Description:
    </i>
    The path to the Kerberos keytab file that you received from your Kerberos administrator. For example,
    <span class="Code" oldrole="userinput">
     kerberos-keytab-file("/opt/syslog-ng/etc/hdfs.headless.keytab")
    </span>
    . This option is needed only if you want to authenticate using Kerberos in Hadoop. You also have to set the
    <a href="destination-hdfs.htm">
     <span class="Code" oldrole="parameter">
      hdfs-option-kerberos-principal()
     </span>
    </a>
    option. For details on the using Kerberos authentication with the
    <span class="Code" oldrole="parameter">
     hdfs()
    </span>
    destination, see
    <xref linkend="destination-hdfs-kerberos-authentication">
    </xref>
    .
   </p>
   <MadCap:snippetBlock src="../../shared/chunk/synopsis-hdfs-kerberos-example.htm">
   </MadCap:snippetBlock>
   <p oldrole="para">
    Available in
    <entity>
     abbrev
    </entity>
    version
    <phrase condition="ose">
     3.10
    </phrase>
    <phrase condition="pe">
     7.0.3
    </phrase>
    and later.
   </p>
  </simplesect>
  <simplesect xml:id="hdfs-option-kerberos-principal">
   <title>
    kerberos-principal()
   </title>
   <indexterm type="parameter">
    <primary>
     kerberos-principal()
    </primary>
    <secondary>
     hdfs
    </secondary>
   </indexterm>
   <indexterm type="parameter">
    <primary>
     hdfs
    </primary>
    <secondary>
     kerberos-principal
    </secondary>
   </indexterm>
   <indexterm>
    <primary>
     kerberos
    </primary>
    <secondary>
     hdfs
    </secondary>
   </indexterm>
   <informaltable colsep="0" frame="topbot" rowsep="0">
    <tgroup cols="2">
     <colspec colnum="1" colwidth="40pt">
     </colspec>
     <tbody>
      <row>
       <entry>
        Type:
       </entry>
       <entry>
        string
       </entry>
      </row>
      <row>
       <entry>
        Default:
       </entry>
       <entry>
        N/A
       </entry>
      </row>
     </tbody>
    </tgroup>
   </informaltable>
   <p oldrole="para">
    <i oldrole="emphasis" role="bold">
     Description:
    </i>
    The Kerberos principal you want to authenticate with. For example,
    <span class="Code" oldrole="userinput">
     kerberos-principal("hdfs-user@MYREALM")
    </span>
    . This option is needed only if you want to authenticate using Kerberos in Hadoop. You also have to set the
    <a href="destination-hdfs.htm">
     <span class="Code" oldrole="parameter">
      hdfs-option-kerberos-keytab-file()
     </span>
    </a>
    option. For details on the using Kerberos authentication with the
    <span class="Code" oldrole="parameter">
     hdfs()
    </span>
    destination, see
    <xref linkend="destination-hdfs-kerberos-authentication">
    </xref>
    .
   </p>
   <MadCap:snippetBlock src="../../shared/chunk/synopsis-hdfs-kerberos-example.htm">
   </MadCap:snippetBlock>
   <p oldrole="para">
    Available in
    <entity>
     abbrev
    </entity>
    version
    <phrase condition="ose">
     3.10
    </phrase>
    <phrase condition="pe">
     7.0.3
    </phrase>
    and later.
   </p>
  </simplesect>
  <simplesect>
   <MadCap:snippetBlock src="../../shared/chunk/option-destination-log-fifo-size.htm">
   </MadCap:snippetBlock>
  </simplesect>
  <simplesect>
   <MadCap:snippetBlock src="../../shared/chunk/option-destination-on-error.htm">
   </MadCap:snippetBlock>
  </simplesect>
  <simplesect>
   <MadCap:snippetBlock src="../../shared/chunk/option-destination-retries.htm">
   </MadCap:snippetBlock>
  </simplesect>
  <simplesect>
   <MadCap:snippetBlock src="../../shared/chunk/option-destination-template.htm">
   </MadCap:snippetBlock>
  </simplesect>
  <simplesect>
   <MadCap:snippetBlock src="../../shared/chunk/option-destination-throttle.htm">
   </MadCap:snippetBlock>
  </simplesect>
  <simplesect>
   <MadCap:snippetBlock src="../../shared/chunk/option-destination-timezone.htm">
   </MadCap:snippetBlock>
  </simplesect>
  <simplesect>
   <MadCap:snippetBlock src="../../shared/chunk/option-destination-ts-format.htm">
   </MadCap:snippetBlock>
  </simplesect>
 </body>
</html>
